{\rtf1\ansi\ansicpg936\cocoartf1504\cocoasubrtf830
{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\fnil\fcharset134 PingFangSC-Regular;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 import pandas as pd\
import numpy as np\
import matplotlib.pyplot as plt\
from sklearn.preprocessing import MinMaxScaler\
from keras.models import Sequential\
from keras.layers import LSTM, Dense, Activation\
\
#
\f1 \'b6\'a8\'d2\'e5\'c4\'a3\'d0\'cd
\f0 \
def create_model():\
    model = Sequential()\
    #
\f1 \'ca\'e4\'c8\'eb\'ca\'fd\'be\'dd\'b5\'c4
\f0 shape
\f1 \'ce\'aa
\f0 (n_samples, timestamps, features)\
    #
\f1 \'d2\'fe\'b2\'d8\'b2\'e3\'c9\'e8\'d6\'c3\'ce\'aa
\f0 256, input_shape
\f1 \'d4\'aa\'d7\'e9\'b5\'da\'b6\'fe\'b8\'f6\'b2\'ce\'ca\'fd
\f0 1
\f1 \'d2\'e2\'d6\'b8
\f0 features
\f1 \'ce\'aa
\f0 1\
    #
\f1 \'cf\'c2\'c3\'e6\'bb\'b9\'d3\'d0\'b8\'f6
\f0 lstm
\f1 \'a3\'ac\'b9\'ca
\f0 return_sequences
\f1 \'c9\'e8\'d6\'c3\'ce\'aa
\f0 True\
    model.add(LSTM(units=256,input_shape=(None,1),return_sequences=True))\
    model.add(LSTM(units=256))\
    #
\f1 \'ba\'f3\'bd\'d3\'c8\'ab\'c1\'ac\'bd\'d3\'b2\'e3\'a3\'ac\'d6\'b1\'bd\'d3\'ca\'e4\'b3\'f6\'b5\'a5\'b8\'f6\'d6\'b5\'a3\'ac\'b9\'ca
\f0 units
\f1 \'ce\'aa
\f0 1\
    model.add(Dense(units=1))\
    model.add(Activation('linear'))\
    model.compile(loss='mse',optimizer='adam')\
    return model\
\
#
\f1 \'b6\'c1\'c8\'a1\'b7\'c5\'d4\'da\'b8\'f9\'c4\'bf\'c2\'bc\'cf\'c2\'b5\'c4
\f0 \'93.csv\'94
\f1 \'ce\'c4\'bc\'fe
\f0 \
df = pd.read_csv('passengers.csv',usecols=['passengers'])\
\
#
\f1 \'ca\'fd\'be\'dd\'b9\'e9\'d2\'bb\'bb\'af\'ba\'f3\'b7\'d6\'b3\'c9\'d0\'f2\'c1\'d0
\f0 \
scaler_minmax = MinMaxScaler()\
data = scaler_minmax.fit_transform(df)\
infer_seq_length = 10#
\f1 \'d3\'c3\'d3\'da\'cd\'c6\'b6\'cf\'b5\'c4\'c0\'fa\'ca\'b7\'d0\'f2\'c1\'d0\'b3\'a4\'b6\'c8
\f0 \
\
d = []\
for i in range(data.shape[0]-infer_seq_length):\
    d.append(data[i:i+infer_seq_length+1].tolist())\
d = np.array(d)\
\
#
\f1 \'bb\'ae\'b7\'d6\'ca\'fd\'be\'dd\'bc\'af
\f0 \
split_rate = 0.9\
X_train, y_train = d[:int(d.shape[0]*split_rate),:-1], d[:int(d.shape[0]*split_rate),-1]\
\
#
\f1 \'b4\'b4\'bd\'a8\'d1\'b5\'c1\'b7\'c4\'a3\'d0\'cd
\f0 \
model =create_model()\
model.fit(X_train, y_train, batch_size=20,epochs=100,validation_split=0.1)\
\
#
\f1 \'d4\'a4\'b2\'e2\'bd\'e1\'b9\'fb
\f0 \
#inverse_transform
\f1 \'bb\'f1\'b5\'c3\'b9\'e9\'d2\'bb\'bb\'af\'c7\'b0\'b5\'c4\'d4\'ad\'ca\'bc\'ca\'fd\'be\'dd
\f0 \
plt.plot(scaler_minmax.inverse_transform(d[:,-1]),label='true data')\
plt.plot(scaler_minmax.inverse_transform(model.predict(d[:,:-1])),'r:',label='predict')\
plt.legend()\
\
plt.plot()\
plt.plot(scaler_minmax.inverse_transform(d[int(len(d)*split_rate):,-1]),label='true data')\
plt.plot(scaler_minmax.inverse_transform(model.predict(d[int(len(d)*split_rate):,:-1])),'r:',label='predict')\
plt.legend()}